apiVersion: v1
kind: ConfigMap
metadata:
  name: accumulo-configmap
  labels:
    app: {{ template "accumulo.name" . }}
    chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+" "_" }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
  accumulo-env.sh: |
    #! /usr/bin/env bash

    export ACCUMULO_LOG_DIR="${ACCUMULO_LOG_DIR:-${basedir}/logs}"
    export ZOOKEEPER_HOME="${ZOOKEEPER_HOME:-/path/to/zookeeper}"

    ## Verify that Hadoop & Zookeeper installation directories exist
    if [[ ! -d "$ZOOKEEPER_HOME" ]]; then
      echo "ZOOKEEPER_HOME=$ZOOKEEPER_HOME is not set to a valid directory in accumulo-env.sh"
      exit 1
    fi

    ## Build using existing CLASSPATH, conf/ directory, dependencies in lib/, and external Hadoop & Zookeeper dependencies
    if [[ -n "$CLASSPATH" ]]; then
      CLASSPATH="${CLASSPATH}:${conf}"
    else
      CLASSPATH="${conf}"
    fi
    CLASSPATH="${CLASSPATH}:${lib}/*:${s3lib}/*:${ZOOKEEPER_HOME}/*"
    CLASSPATH="${CLASSPATH}:${ZOOKEEPER_HOME}/lib/*"
    export CLASSPATH

    ## JVM options set for all processes. Extra options can be passed in by setting ACCUMULO_JAVA_OPTS to an array of options.
    JAVA_OPTS=($ACCUMULO_JAVA_OPTS
      '-XX:OnOutOfMemoryError=kill -9 %p'
      '-XX:-OmitStackTraceInFastThrow'
      '-Djava.net.preferIPv4Stack=true'
      "-Daccumulo.native.lib.path=${lib}/native")

    ## Make sure Accumulo native libraries are built since they are enabled by default
    "${bin}"/accumulo-util build-native &> /dev/null

    ## JVM options set for individual applications
    case "$cmd" in
      manager|master)  JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.manager.javaOpts.memory }}) ;;
      monitor) JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.monitor.javaOpts.memory }}) ;;
      gc)      JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.gc.javaOpts.memory }}) ;;
      tserver) JAVA_OPTS=("${JAVA_OPTS[@]}" {{ .Values.accumulo.tserver.javaOpts.memory }}) ;;
      compaction-coordinator) JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx512m' '-Xms512m') ;;
      compactor) JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx256m' '-Xms256m') ;;
      *)       JAVA_OPTS=("${JAVA_OPTS[@]}" '-Xmx256m' '-Xms64m') ;;
    esac

    ## JVM options set for logging. Review log4j2.properties file to see how they are used.
    JAVA_OPTS=("${JAVA_OPTS[@]}"
      "-Daccumulo.log.dir=${ACCUMULO_LOG_DIR}"
      "-Daccumulo.application=${cmd}${ACCUMULO_SERVICE_INSTANCE}_$(hostname)"
      "-Daccumulo.metrics.service.instance=${ACCUMULO_SERVICE_INSTANCE}"
      "-Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector"
      "-Dotel.service.name=${cmd}${ACCUMULO_SERVICE_INSTANCE}"
    )

    case "$cmd" in
      monitor|gc|manager|master|tserver|compaction-coordinator|compactor)
        JAVA_OPTS=("${JAVA_OPTS[@]}" "-Dlog4j.configurationFile=log4j2-service.properties")
        ;;
      *)
        # let log4j use its default behavior (log4j2.properties, etc.)
        true
        ;;
    esac

    export MALLOC_ARENA_MAX=${MALLOC_ARENA_MAX:-1}

  accumulo.properties: |
    ## Sets location of Zookeepers
    instance.zookeeper.host={{ .Values.zookeeper.host }}

    ## Change secret before initialization. All Accumulo servers must have same secret
    instance.secret=DEFAULT

    ## Set to false if 'accumulo-util build-native' fails
    tserver.memory.maps.native.enabled=true

    ## S3 specific deployment configurations
    ## For S3 you must define volumes for accumulo and its write ahead logs. Replace the defaule instance volumes at the top
    ## with the example below. Make sure the volumes match the general.custom.volume.preferred.default, and
    ## general.custom.volume.preferred.logger property values below
    instance.volumes=s3a://{{ .Values.s3.bucket }}/accumulo,file:/{{ .Values.s3.bucket }}/accumulo-wal

    ## Define the S3 objects to use for recording accumulo and write ahead log data
    general.custom.volume.preferred.default=s3a://{{ .Values.s3.bucket }}/accumulo
    general.custom.volume.preferred.logger=file:/{{ .Values.s3.bucket }}/accumulo-wal

    ## The default deployment will use a RandomVolumeChooser and HadoopLogCloser and neither of which work when deploying to
    ## S3. Remove the comments below to use the volume chooser and log closer that are compatible with S3
    general.volume.chooser=org.apache.accumulo.core.spi.fs.PreferredVolumeChooser
    manager.walog.closer.implementation=org.apache.accumulo.server.manager.recovery.NoOpLogCloser

  accumulo-client.properties: |
    instance.name={{ .Values.accumulo.instance_name }}
    instance.zookeepers={{ .Values.zookeeper.host }}
    #instance.zookeepers.timeout=30s
    auth.type=password
    auth.principal={{ .Values.accumulo.username }}
    auth.token={{ .Values.accumulo.passwd }}

  core-site.xml: |
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>s3a://{{ .Values.s3.bucket }}</value>
        </property>
        <property>
            <name>fs.s3a.impl</name>
            <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
        </property>
        <property>
            <name>fs.s3a.downgrade.syncable.exceptions</name>
            <value>true</value>
        </property>

        {{- if .Values.s3.key -}}
        <property>
            <name>fs.s3a.access.key</name>
            <value>{{ .Values.s3.key }}</value>
        </property>
        {{- end -}}

        {{- if .Values.s3.secret -}}
        <property>
            <name>fs.s3a.secret.key</name>
            <value>{{ .Values.s3.secret }}</value>
        </property>
        {{- end -}}

        {{- if .Values.s3.token -}}
        <property>
            <name>fs.s3a.session.token</name>
            <value>{{ .Values.s3.token }}</value>
        </property>
        {{- end -}}

        {{- if .Values.s3.endpoint -}}
        <property>
          <name>fs.s3a.endpoint</name>
          <value>{{ .Values.s3.endpoint }}</value>
        </property>
        {{- end -}}

        {{- if .Values.s3.endpoint -}}
        <property>
          <name>fs.s3a.path.style.access</name>
          <value>{{ .Values.s3.path_style_access }}</value>
        </property>
        {{- end -}}

        <property>
            <name>fs.s3a.connection.ssl.enabled</name>
            <value>{{ .Values.s3.ssl_enabled }}</value>
        </property>
    </configuration>

  log4j2.properties: |
    status = info
    dest = err
    name = AccumuloDefaultLoggingProperties
    monitorInterval = 30

    appender.console.type = Console
    appender.console.name = STDERR
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %style{%d{ISO8601}}{dim,cyan} %style{[}{red}%style{%C}{dim,blue}%style{]}{red} %highlight{%-5p}%style{:}{red} %m%n

    logger.shellaudit.name = org.apache.accumulo.shell.Shell.audit
    logger.shellaudit.level = warn

    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = error

    rootLogger.level = info
    rootLogger.appenderRef.console.ref = STDERR

  bootstrap.sh: |
    #!/bin/bash

    # Directory to find config artifacts
    CONFIG_DIR="/tmp/accumulo-config"

    # delete the old log4j properties file before replacing it with our own
    mv /opt/accumulo/conf/log4j2.properties /opt/accumulo/conf/log4j2.properties.orig

    # Copy accumulo config files from volume mount
    for f in accumulo.properties accumulo-env.sh accumulo-client.properties core-site.xml log4j2.properties; do
      if [[ -e ${CONFIG_DIR}/$f ]]; then
        cp ${CONFIG_DIR}/$f /opt/accumulo/conf/$f
      else
        echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
      fi
    done

    # make manager config
    manager_end=$(({{ .Values.accumulo.manager.replicas }} - 1))
    for i in $(seq 0 $manager_end);
      do
        #echo "{{ template "accumulo.fullname" . }}-manager-$i" >> /opt/accumulo/conf/managers;
        echo "{{ template "accumulo.fullname" . }}-manager-$i" >> /opt/accumulo/conf/masters;
        echo "{{ template "accumulo.fullname" . }}-manager-$i" >> /opt/accumulo/conf/gc;
        echo "{{ template "accumulo.fullname" . }}-manager-$i" >> /opt/accumulo/conf/monitor;
    done

    # make tserver config
    tserver_end=$(({{ .Values.accumulo.tserver.replicas }} - 1))
    for i in $(seq 0 $tserver_end);
      do
        echo "{{ template "accumulo.fullname" . }}-ts-$i" >> /opt/accumulo/conf/tservers;
    done

  manager.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo manager

  tserver.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo tserver

  gc.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo gc

  monitor.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    /opt/accumulo/bin/accumulo monitor

  init.sh: |
    #!/bin/bash

    /bin/bash /tmp/accumulo-config/bootstrap.sh
    # only run init container once even with multiple managers, so on the first manager pod only
    if [[ "${HOSTNAME}" =~ "accumulo-manager-0" ]]; then
      if {{ .Values.accumulo.init }}; then
        rm -rf /{{ .Values.s3.bucket }}/accumulo-wal/*
        $ACCUMULO_HOME/bin/accumulo init \
        --force \
        --clear-instance-name \
        --instance-name {{ .Values.accumulo.instance_name }} \
        --password {{ .Values.accumulo.passwd }} \
        --user {{ .Values.accumulo.username }}
        sleep 2
        ls -lah /{{ .Values.s3.bucket }}/accumulo-wal/
      fi
    fi

  ts-wait.sh: |
    #!/bin/bash

    echo "Waiting for manager on 9999..."
    while ! nc -z {{ template "accumulo.fullname" . }}-manager-0 9999; do
      sleep 0.1 # wait for 1/10 of the second before check again
    done

